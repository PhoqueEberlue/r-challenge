Pour cet essai nous avons utilisé la méthode random forest. La librairie utilisé est 'randomForest'.

Nous optenons 0.9161905 de bonne classification en coupant nos données en entraînement et en test.
En cross validating nous obtenons étonnament une meilleure classification : 0.9201905

Nous n'avons pas grand chose à ajouter par rapport aux précédent dépôt car nous avons seuelement changé la méthode de classification
ainsi que le % de répartition des données dans le cross validating.

Vous trouverez également quelques images montrant les graphs qui nous ont permi de trouver des valeurs idéales de lowFreq / highFreq

Sources utilisées :
https://thinkr.fr/premiers-pas-en-machine-learning-avec-r-volume-4-random-forest/
https://www.r-bloggers.com/2018/01/how-to-implement-random-forests-in-r/
https://cran.r-project.org/web/packages/randomForest/randomForest.pdf